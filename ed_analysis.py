# -*- coding: utf-8 -*-
"""ED ANALYSIS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13AGc6T5nQCkClC3EJh6mcRig7vqOj2or
"""

pip install pandas

pip install matplotlib

pip install seaborn

pip install wordcloud

pip install scikit-learn

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from datetime import datetime

# Ensure inline plotting works
# %matplotlib inline

# Suppress warnings for cleaner output
import warnings
warnings.filterwarnings('ignore')

# Load data (replace 'your_file.csv' with your actual dataset)
file_path = "/content/cmrit.bangalore_instagram_data.csv"  # Update with your dataset's path

try:
    # Specify 'latin1' or 'ISO-8859-1' encoding to handle non-UTF-8 characters
    data = pd.read_csv(file_path, encoding='latin1')
    print("Data loaded successfully!")
    print(data.head())  # Display the first few rows of the dataset
except FileNotFoundError:
    print("Error: Dataset file not found. Please provide the correct file path.")
except UnicodeDecodeError as e:
    print(f"UnicodeDecodeError: {e}")
    print("Try using a different encoding like 'latin1' or 'ISO-8859-1'.")

print("All libraries loaded successfully!")

print(data.info())

data.describe()

from datetime import datetime

# Convert 'date' to datetime format with the correct format
data['date'] = pd.to_datetime(data['date'], format='%d-%m-%Y %H:%M')

# Create separate columns for date, time, hour, and day
data['date_only'] = data['date'].dt.date  # Extracts the date
data['time'] = data['date'].dt.time       # Extracts the time
data['hour'] = data['date'].dt.hour       # Extracts the hour
data['day'] = data['date'].dt.day_name()  # Extracts the day of the week

# Display the first few rows to check the result
print(data.head())

print(data.isnull().sum())

import matplotlib.pyplot as plt
import pandas as pd

# Group data by day of the week and calculate the average likes
likes_by_day = data.groupby('day')['likes'].mean().reindex(
    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
)

# Plot the likes versus day
plt.figure(figsize=(10, 6))
likes_by_day.plot(kind='bar', color='skyblue', edgecolor='black')

# Add labels, title, and grid
plt.title('Average Likes per Day of the Week', fontsize=16)
plt.xlabel('Day of the Week', fontsize=14)
plt.ylabel('Average Likes', fontsize=14)
plt.xticks(rotation=45, fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Show the plot
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import pandas as pd

# Group data by day of the week and calculate the average likes
likes_by_day = data.groupby('day')['comments'].mean().reindex(
    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
)

# Plot the likes versus day
plt.figure(figsize=(10, 6))
likes_by_day.plot(kind='bar', color='skyblue', edgecolor='black')

# Add labels, title, and grid
plt.title('Average Comments per Day of the Week', fontsize=16)
plt.xlabel('Day of the Week', fontsize=14)
plt.ylabel('Average Comments', fontsize=14)
plt.xticks(rotation=45, fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Show the plot
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import pandas as pd

# Group data by day of the week and calculate the average likes
likes_by_day = data.groupby('day')['shares'].mean().reindex(
    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
)

# Plot the likes versus day
plt.figure(figsize=(10, 6))
likes_by_day.plot(kind='bar', color='skyblue', edgecolor='black')

# Add labels, title, and grid
plt.title('Average Shares per Day of the Week', fontsize=16)
plt.xlabel('Day of the Week', fontsize=14)
plt.ylabel('Average Shares', fontsize=14)
plt.xticks(rotation=45, fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Show the plot
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Assuming the 'data' DataFrame already contains a 'day' and 'shares' column

# Binning and grouping data by day
shares_by_day = data.groupby('day')['shares'].sum().reindex(
    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
)

# Plotting the results
plt.figure(figsize=(10, 6))
shares_by_day.plot(kind='bar', color='orange', edgecolor='black')

# Adding labels, title, and grid
plt.title('Total Shares per Day of the Week', fontsize=16)
plt.xlabel('Day of the Week', fontsize=14)
plt.ylabel('Total Shares', fontsize=14)
plt.xticks(rotation=45, fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Show the plot
plt.tight_layout()
plt.show()

# Engagement by Day
daily_engagement = data.groupby('day')[['likes', 'comments', 'shares']].mean()
daily_engagement.plot(kind='bar', figsize=(12, 6), stacked=True)
plt.title('Engagement by Day of Week')
plt.xlabel('Day')
plt.ylabel('Average Engagement')
plt.show()

# Classify posts into 'Weekday' or 'Weekend'
data['is_weekend'] = data['day'].apply(lambda x: 'Weekend' if x in ['Saturday', 'Sunday'] else 'Weekday')

# Average engagement for Weekdays vs Weekends
weekend_engagement = data.groupby('is_weekend')[['likes', 'comments', 'shares']].mean()

# Plot the results
weekend_engagement.plot(kind='bar', figsize=(10, 6), color=['#1f77b4', '#ff7f0e', '#2ca02c'], stacked=True)
plt.title('Engagement on Weekends vs Weekdays')
plt.ylabel('Average Engagement')
plt.xlabel('Day Type')
plt.xticks(rotation=0)
plt.show()

# Define a threshold for "high-performing" posts based on likes
likes_threshold = data['likes'].mean() + data['likes'].std()

# Filter high-performing posts based on likes
high_performing_posts_likes = data[data['likes'] > likes_threshold]

# Display high-performing post details based on likes
print(high_performing_posts_likes[['date', 'caption', 'hashtags', 'likes', 'comments', 'shares', 'post_url']])

# Save to a CSV file for further analysis
high_performing_posts_likes.to_csv("high_performing_posts_likes.csv", index=False)

# Visualize the likes of high-performing posts
plt.figure(figsize=(10, 6))
sns.barplot(
    data=high_performing_posts_likes,
    x='date',
    y='likes',
    hue='is_weekend',
    dodge=False
)
plt.title('High-Performing Posts Likes')
plt.ylabel('Likes')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.legend(title="Weekend/Weekday")
plt.show()

# Define a threshold for "high-performing" posts based on comments
comments_threshold = data['comments'].mean() + data['comments'].std()

# Filter high-performing posts based on comments
high_performing_posts_comments = data[data['comments'] > comments_threshold]

# Display high-performing post details based on comments
print(high_performing_posts_comments[['date', 'caption', 'hashtags', 'likes', 'comments', 'shares', 'post_url']])

# Save to a CSV file for further analysis
high_performing_posts_comments.to_csv("high_performing_posts_comments.csv", index=False)

# Visualize the comments of high-performing posts
plt.figure(figsize=(10, 6))
sns.barplot(
    data=high_performing_posts_comments,
    x='date',
    y='comments',
    hue='is_weekend',
    dodge=False
)
plt.title('High-Performing Posts comments')
plt.ylabel('Comments')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.legend(title="Weekend/Weekday")
plt.show()

# Define a threshold for "high-performing" posts based on shares
shares_threshold = data['shares'].mean() + data['shares'].std()

# Filter high-performing posts based on shares
high_performing_posts_shares = data[data['shares'] > shares_threshold]

# Display high-performing post details based on shares
print(high_performing_posts_shares[['date', 'caption', 'hashtags', 'likes', 'comments', 'shares', 'post_url']])

# Save to a CSV file for further analysis
high_performing_posts_shares.to_csv("high_performing_posts_shares.csv", index=False)

# Visualize the shares of high-performing posts
plt.figure(figsize=(10, 6))
sns.barplot(
    data=high_performing_posts_shares,
    x='date',
    y='shares',
    hue='is_weekend',
    dodge=False
)
plt.title('High-Performing Posts Shares')
plt.ylabel('Shares')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.legend(title="Weekend/Weekday")
plt.show()

plt.figure(figsize=(12, 6))
sns.histplot(data['likes'], kde=True, color='blue')
plt.title('Distribution of Likes')
plt.show()

plt.figure(figsize=(12, 6))
sns.histplot(data['comments'], kde=True, color='green')
plt.title('Distribution of Comments')
plt.show()

plt.figure(figsize=(12, 6))
sns.histplot(data['shares'], kde=True, color='orange')
plt.title('Distribution of Shares')
plt.show()

correlation_matrix = data[['likes', 'comments', 'shares']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Between Likes, Comments, and Shares')
plt.show()

# Insights on Captions
captions = ' '.join(data['caption'])
wordcloud_captions = WordCloud(width=800, height=400, background_color='white').generate(captions)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_captions, interpolation='bilinear')
plt.axis('off')
plt.title('Most Frequent Words in Captions')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Assuming 'data' DataFrame contains 'caption', 'likes', 'comments', and 'shares'

# Define frequently used words
frequent_words = [
    "CMRIT", "Institution", "Innovation", "Department", "MHRD", "Council", "IIC",
    "Engineering", "Workshop", "Talk", "CMRITBengaluru", "Excellence",
    "IIC_CMRIT", "ArtificialIntelligence", "Startup", "Entrepreneurship", "ExpertTalk"
]

# Initialize a list to store results
engagement_results = []

# Loop through each word and calculate average engagement
for word in frequent_words:
    # Filter posts containing the word in the caption only
    filtered_posts = data[data['caption'].str.contains(word, case=False, na=False)]

    # Calculate average engagement (likes + comments + shares)
    if not filtered_posts.empty:
        avg_engagement = (filtered_posts['likes'] + filtered_posts['comments'] + filtered_posts['shares']).mean()
    else:
        avg_engagement = 0  # If no posts contain the word

    # Append results to the list
    engagement_results.append({'Word': word, 'Average Engagement': avg_engagement})

# Convert results to a DataFrame
engagement_df = pd.DataFrame(engagement_results)

# Sort by average engagement for better readability
engagement_df = engagement_df.sort_values(by='Average Engagement', ascending=False)

# Display the results
print(engagement_df)

# Plot the results as a pie chart
plt.figure(figsize=(10, 8))
plt.pie(
    engagement_df['Average Engagement'],
    labels=engagement_df['Word'],
    autopct='%1.1f%%',
    startangle=140,
    colors=plt.cm.Paired.colors
)

# Add title
plt.title('Proportion of Average Engagement by Frequent Words in Caption', fontsize=16)

# Equal aspect ratio ensures the pie chart is circular
plt.tight_layout()
plt.show()

# Define post categories based on captions or hashtags
def categorize_post(caption):
    if "event" in caption.lower():
        return "Event"
    elif "achievement" in caption.lower():
        return "Achievement"
    elif "congratulations" in caption.lower():
        return "Congratulations"
    elif "admission" in caption.lower():
        return "Admission"
    else:
        return "General"

data['post_type'] = data['caption'].apply(categorize_post)

# Average engagement by post type
post_type_engagement = data.groupby('post_type')[['likes', 'comments', 'shares']].mean()
post_type_engagement.plot(kind='bar', figsize=(10, 6), stacked=True, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
plt.title('Average Engagement by Post Type')
plt.ylabel('Average Engagement')
plt.show()

# Identify department-related posts
def department_category(caption):
    if "cse" in caption.lower():
        return "CSE"
    if "ise" in caption.lower():
        return "ISE"
    elif "ece" in caption.lower():
        return "ECE"
    elif "ai" in caption.lower():
        return "AI"
    elif "mba" in caption.lower():
        return "MBA"
    elif "mca" in caption.lower():
        return "MCA"
    else:
        return "Others"

data['department'] = data['caption'].apply(department_category)

# Average engagement by department
department_engagement = data.groupby('department')[['likes', 'comments', 'shares']].mean()
department_engagement.plot(kind='bar', figsize=(10, 6), stacked=True, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
plt.title('Average Engagement by Department')
plt.ylabel('Average Engagement')
plt.xlabel('Department')
plt.show()

# Filter the posts where the caption length is >= 500
posts_with_long_caption = data[data['caption'].str.len() >= 500][['date', 'likes', 'caption']]

# Display the filtered posts with date, likes, and caption
print(posts_with_long_caption)

# Calculate caption length
data['caption_length'] = data['caption'].apply(len)

# Plot engagement vs. caption length
sns.jointplot(data=data, x='caption_length', y='likes', kind='scatter', color='blue')
plt.suptitle('Caption Length vs. Likes', y=1.02)
plt.show()

sns.jointplot(data=data, x='caption_length', y='comments', kind='scatter', color='orange')
plt.suptitle('Caption Length vs. Comments', y=1.02)
plt.show()

sns.jointplot(data=data, x='caption_length', y='shares', kind='scatter', color='green')
plt.suptitle('Caption Length vs. Shares', y=1.02)
plt.show()

# WordCloud for Hashtags
hashtags = ' '.join(data['hashtags'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(hashtags)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Most Frequent Hashtags')
plt.show()

# Explode hashtags into individual words
data['hashtags_list'] = data['hashtags'].apply(lambda x: x.split())
hashtags_exploded = data.explode('hashtags_list')

# Top 10 hashtags by average engagement
top_hashtags = (
    hashtags_exploded.groupby('hashtags_list')[['likes', 'comments', 'shares']]
    .mean()
    .sort_values('likes', ascending=False)
    .head(10)
)
top_hashtags.plot(kind='bar', figsize=(10, 6), color=['#1f77b4', '#ff7f0e', '#2ca02c'])
plt.title('Top 10 Hashtags by Average Engagement')
plt.ylabel('Average Engagement')
plt.xlabel('Hashtags')
plt.show()

# Count the number of hashtags in each post
data['num_hashtags'] = data['hashtags'].apply(lambda x: len(x.split()))

# Engagement by number of hashtags
hashtag_engagement = data.groupby('num_hashtags')[['likes', 'comments', 'shares']].mean()
hashtag_engagement.plot(kind='line', figsize=(12, 6), marker='o')
plt.title('Engagement by Number of Hashtags')
plt.xlabel('Number of Hashtags')
plt.ylabel('Average Engagement')
plt.show()

# Group by 'hour' and calculate the average number of likes for each hour
likes_by_hour = data.groupby('hour')['likes'].mean()

# Plot the results
plt.figure(figsize=(10, 6))
sns.lineplot(x=likes_by_hour.index, y=likes_by_hour.values, marker='o')

# Adding labels and title
plt.title('Average Likes by Hour of the Day', fontsize=16)
plt.xlabel('Hour of the Day', fontsize=12)
plt.ylabel('Average Likes', fontsize=12)
plt.grid(True)

# Display the plot
plt.show()

# Group by 'hour' and calculate the average number of likes for each hour
likes_by_hour = data.groupby('hour')['comments'].mean()

# Plot the results
plt.figure(figsize=(10, 6))
sns.lineplot(x=likes_by_hour.index, y=likes_by_hour.values, marker='o')

# Adding labels and title
plt.title('Average Comments by Hour of the Day', fontsize=16)
plt.xlabel('Hour of the Day', fontsize=12)
plt.ylabel('Average Comments', fontsize=12)
plt.grid(True)

# Display the plot
plt.show()

# Group by 'hour' and calculate the average number of likes for each hour
likes_by_hour = data.groupby('hour')['shares'].mean()

# Plot the results
plt.figure(figsize=(10, 6))
sns.lineplot(x=likes_by_hour.index, y=likes_by_hour.values, marker='o')

# Adding labels and title
plt.title('Average Shares by Hour of the Day', fontsize=16)
plt.xlabel('Hour of the Day', fontsize=12)
plt.ylabel('Average Shares', fontsize=12)
plt.grid(True)

# Display the plot
plt.show()

# Engagement based on Posting Hour
hourly_engagement = data.groupby('hour')[['likes', 'comments', 'shares']].mean()
hourly_engagement.plot(kind='bar', figsize=(12, 6), stacked=True)
plt.title('Engagement by Posting Hour')
plt.xlabel('Hour of Day')
plt.ylabel('Average Engagement')
plt.show()

# Group by date to observe trends
daily_trends = data.groupby('date')[['likes', 'comments', 'shares']].sum()

# Plot engagement trends over time
daily_trends.plot(figsize=(14, 6))
plt.title('Engagement Trends Over Time')
plt.xlabel('Date')
plt.ylabel('Total Engagement')
plt.show()